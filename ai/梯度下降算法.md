#  梯度下降算法

### 梯度下降算法的原理

#### 对于一元的凸函数


$$
x^{n+1}=x^n-\eta\frac{\partial f}{\partial x}
$$
​     直至找到最后的x使f的最小极值 

#### 对于多元的凸函数 

$$
x^{k+1}=x^k-\eta \frac{\partial f}{\partial x}
$$

$$
y^{k+1}=y^k-\eta \frac{\partial f}{\partial x}
$$

$$
\dots
$$

总结，对于loss函数能表示为凸函数的情况一定可以使用梯度下降算法，最快找到极小值。

###  梯度下降法解决一元线性回归问题

一元函数中损失函数
$$
Loss=\frac{1}{2}\sum_1^n(y_i-(wx_i+b))^2=\sum_1^n(x_i^2w^2+b^2+2x_iwb-2y_ib-2x_iy_iw+y_i^2)
$$
这样一来一元损失函数就转化为Loss（w，b）的极值问题

### 梯度下降算法解决多元线性问题



学习率/eta的值过小效率会低，过大则产生震荡。

